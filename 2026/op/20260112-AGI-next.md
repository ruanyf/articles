## 国产 AI 峰会 AGI-Next

https://www.53ai.com/news/LargeLanguageModel/2026011069524.html

AGI-Next前沿峰会，汇集了

唐杰：清华大学教授，智谱创始人

杨植麟：月之暗面 Kimi 创始人

林俊旸：阿里 Qwen 负责人

曾任OpenAI核心研究者、现为腾讯AI新部门负责人的姚顺雨，针对路线分化、自主学习、Agent战略和中国反超机率四大议题展开讨论。

美中AI竞争，中国顶尖的AI大模型领导者齐聚一堂，和外界打鸡血不同，他们更冷静自评整体行业反超的机率低过20%，算力的规模小太多，而且确实美中的研究和企业的AI Lab都有差距。但是他们“穷有穷的做法”。

与会者普遍认为，大模型竞争已从聊天能力转向能完成复杂任务的智能体阶段。 2026年将是模型真正创造商业价值的关键年份，但多位核心人物将中国在下一代范式中领先的机率评估为不超过20%。

### 产业现况：Chat时代结束，做事时代开始

唐杰直言：「DeepSeek出来后，Chat这一代问题基本已经解决。继续优化大概率只是性能接近，或在个性化、情感化上做改进，空间正在迅速收敛。」

这迫使团队思考下一步。 「新的范式不再只是对话，而是让每个人真正用AI完成一件具体的事情。从Chat走向做事，是明显的转折点。」智谱团队最终把所有精力放在了Coding上。

RLVR（可验证强化学习）成为当前关键技术路径。唐杰解释：「过去强化学习难以大规模推进，核心是依赖人类反馈，噪音大、覆盖场景有限。引入可验证环境后，模型可以自主探索、自动获得反馈。但难点在于，数学、编程等领域容易定义可验证，网页是否美观、交互是否合理仍需人工判断。当前RLVR面临的挑战是：可验证场景正在逐渐耗尽。」

杨植麟则从Scaling Law角度分析：「今天所有模型架构的迭代，都是为了寻找一条更接近左下角的线。互联网存量数据有限，高品质数据成长速度赶不上模型迭代速度，所以Token efficiency决定智能上限。」他透露Kimi采用的MUON二阶优化器带来两倍Token efficiency提升，而新架构Kimi Linear在百万Context下速度优势达6到10倍。

林俊旸观察到中美市场差异：「跟美国API厂商聊，他们没想到Coding消耗量那么大。在美国基本全都是Coding，中国真的没那么大。」他也指出中国开源模型的成就：「在Artificial Analysis榜单上，前五名中的蓝色模型几乎全部来自中国，说明中国在开源大模型领域已经形成非常显著的影响力。」

### ToB与ToC的路线分化

姚顺雨指出toC和toB的逻辑正在分化：「我们今天用ChatGPT和去年相比感受差别不大，但Coding已经在重塑整个电脑行业做事的方式。对于toC，大部分人不需要用到这么强的智能；但对于toB，智能越高代表生产力越高。」

他解释溢价逻辑：「一个年薪20万美元的人，每天做10个任务，强模型可能做对八九个，差的做对五六个。问题是你不知道哪五六个是对的，需要额外精力监控。所以很多人愿意花200美元/月用最好的模型。」

垂直整合也不再是唯一答案。姚顺雨观察：「在toC应用上垂直整合还成立，但对于toB趋势似乎相反。模型层偏向硬核工业化，拼预训练与算力；应用层偏向业务工程化，拼流程与交付。未来toB市场可能走向分层结构：最强的模型配合最懂场景的应用团队。」

### 自主学习已经在发生

姚顺雨认为自主学习是现在进行式：「ChatGPT在利用用户数据学习聊天风格，Claude已经写了这个项目95%的程式码。很多人说2026年看到信号，我觉得2025年就看到了。Cursor每几个小时都会用最新用户数据学习。」

他提出关键问题：「最大的问题是想像力。如果2026年我们宣布实现了自我学习，应该用什么任务衡量？是一个赚钱的交易系统，还是解决了人类之前没法解决的科学问题？」

林俊旸关注主动性带来的安全顾虑：「AI有没有可能自主思考去做事情？我最担心的不是它讲不该说的话，而是做不该做的事。就像培养小孩，要给它注入正确的方向。」

唐杰对2026年范式革新充满信心：「原来工业界有1万片卡，学校是0片，现在很多学校已经有卡了。创新的出现一定是某个事情有大量投入，且efficiency变成瓶颈。继续Scaling有收益，但花掉20亿收益很小就不值得了。也许我们未来可以定义Intelligence efficiency，用多少投入能获得智能的增量。」

他也点出下一步技术方向：「多模态感知统合会成为今年重点。人通过视觉、听觉、触觉形成整体认知，模型如何建立类似的原生多模态机制是关键方向。记忆与持续学习、反思与自我认知能力，都有可能出现新范式变革。」

### Agent之年的展望

姚顺雨分享关键观察：「即使今天模型不再变好，把这些模型部署到各种公司，已经能带来今天10倍或100倍的收益，能对GDP产生5%-10%的影响，但今天影响还不到1%。」

他强调教育的重要性：「中国能做到最大有意义的事情是更好的教育。更多时候不是AI替代人类工作，而是会使用工具的人在替代不会使用工具的人。」

林俊旸指出长尾问题是AGI的魅力：「今天一个用户寻遍各处都找不到能帮他解决问题的，但在那一刻感受到AI的能力，这就是AI最大的魅力。」

他也点出当前局限：「我们现在交互的环境还不够复杂，都是电脑环境。做AlphaFold距离制药还有一段距离，因为要做实验才能得到反馈。有没有可能未来AI环境复杂到真实世界，指挥机器人做实验？这要跟具身智能结合。」

唐杰提出Agent落地的关键因素：「第一，Agent有没有解决有价值的事情；第二，Cost有多大；第三，做应用的速度。大模型现在更多是拼速度、拼时间。」

### 中国反超的机率约20 %

关于「中国能否反超」这一议题，峰会呈现出一种「结构性冷静」。尽管市场热衷于讨论「崛起」与「占榜」，但与会者普遍将中国领先新范式的机率上限压至20%。

### 新范式是唯一要解决的问题

姚顺雨对中国反超持审慎乐观态度：「机率还挺高的，我还是挺乐观的。任何事情一旦被发现，在中国就能很快复现，在很多局部做的更好，包括之前制造业、电动车这样的例子已经不断发生。」

但他随即指出核心挑战：「中国想要突破新范式或做非常冒险事情的人可能还不够多，这里面有经济环境、商业环境包括文化的因素。

我们到底能不能引领新的范式，这可能是今天中国唯一要解决的问题，因为其他所有做的事情，无论是商业、产业设计还是做工程，我们某种程度上已经比美国做的更好。 」

他也点出几个客观限制因素：「一个是中国的光刻机到底能不能突破，如果最终算力变成Bottleneck，我们能不能解决算力问题。目前我们有很好的电力优势、基础设施优势，主要瓶颈是产能、光刻机，以及软体生态。

另一个问题是除了toC之外，能不能有更成熟的toB市场，或者有没有机会在国际商业环境竞争。今天很多做生产力或toB的模型应用还是诞生在美国，因为支付意愿更强、文化更好。 」

### 文化积累与榜单束缚

姚顺雨特别提到文化积累的重要性：「可能不只是大家更喜欢做确定性的事情、不太愿意做创新性的事情，很重要的一点是文化的积累或者整体的认知，其实是需要时间沉淀的事情。OpenAI在2022年就开始做这个事情了，国内2023年开始做，对这个东西的理解会有一些差异。我觉得可能很多也就是时间问题。」

他以DeepSeek和Claude为例说明榜单思维的问题：「中国对刷榜或数字看的更重。DeepSeek做的比较好的一点，是他们可能没有那么关注榜单的数字，更注重什么是正确的事情、什么是你自己能体验出好或不好的。

你看Claude模型可能在编程或软体工程的榜单上也不是最高的，但大家都知道这个东西是最好用的。我觉得这还是需要大家能够走出这些榜单的束缚，能够坚持自己觉得是不是正确的过程。 」

### 算力投入结构的本质差异

阿里千问技术负责人林俊旸从算力投入角度给出更谨慎的评估：「美国的Computer可能整体比我们大1-2个数量级，但我看到不管是OpenAI还是什么，他们大量的Computer投入到的是下一代的Research当中去。

我们今天相对来说捉襟见肘，光交付可能就已经占据了我们绝大部分的Computer，这会是一个比较大的差异。 」

但他也看到穷则生变的机会：「创新是发生在有钱人手里，还是穷人手里？穷人不是没有机会，我们觉得这些富哥真的很浪费卡，他们训了很多可能也没什么用。但今天穷的话，比如今天所谓的演算法Infra联合优化的事情，如果你真的很富，就没有什么动力去做这个事情。」

林俊旸分享了一个遗憾的故事：「2021年我在做大模型，因为阿里做晶片，他们找我说能不能预测一下三年之后这个模型是不是Transformer、是不是多模态。

我当时的回答是三年之后在不在阿里巴巴我都不知道！但我今天还在阿里巴巴，它果然还是Transformer，果然还是多模态。我非常懊悔为什么当时没有催他去做。这个机会有没有可能再来一次？我们虽然是一群穷人，是不是穷则生变，创新的机会会不会发生在这里？ 」

对于年轻一代，他保持乐观：「今天大家的冒险精神开始变的更好。美国人天然有非常强烈的冒险精神，当时电动车刚出来，甚至天棚漏水、开车会意外身亡的情况下，依然会有很多富豪们都愿意去做这个事情。中国的营商环境也在变的更好的情况下，我觉得是有可能带来一些创新的。」

「机率没那么大，但真的有可能。20%吧，已经非常乐观了。今天你干这一行就不能恐惧，必须得有非常强的心态。」他补充道，

「我觉得还是看初心，我们的模型为人类社会带来什么价值。只要能为人类社会带来充分价值，就算不是最强的，我也愿意接受。」

笨笨的坚持

唐杰首先承认差距：「确实要承认在中美，无论是做研究，尤其是企业界的AI Lab，我觉得和美国是有差距的。但我觉得未来中国现在慢慢变的越来越好，尤其是90后、00后这一代，远远好过之前。」

他提出中国可能的三个机会：「第一，一群聪明人真的敢做特别冒险的事，90后、00后这一代是有的，包括俊旸、Kimi、顺雨都非常愿意冒风险来做这样的事情。

第二，我们的环境可能更好一些，无论是国家的环境、大企业和小企业之间的竞争、营商环境。像俊旸说的，他还在做交付，如果把这个环境建设的更好，让敢于冒险的聪明人有更多的时间去做创新的事情，这是政府和国家可以帮忙改善的事情。

第三，回到每个人自己身上，我们能不能坚持，能不能愿意在一条路上敢做、敢冒险。 」

「我觉得环境肯定不会是最好的，永远不会想着环境是最好的。我们恰恰是幸运，我们经历环境从原来没那么好到慢慢变得更好的一个时代。我们是经历者，也许就是财富，包括经历收获最多的人。如果我们笨笨的坚持，也许走到最后的就是我们。」唐杰总结道。

## 唐杰

2019年，我们实验室在图神经网络、知识图谱方面，在国际上做的还行，但当时我们坚定地把这两个方向暂停了，暂时不做了，所有的人都转向做大模型，所有的人开始启动了大模型相关的研究。

模型从 Scaling（规模）到泛化？

我们人一直都希望机器有泛化能力，我教它一点点，它就能举一反三，其实就和人一样。我们在教一个小孩子的时候，我们总希望教小孩子三个问题，他就会第四个、会第十个，甚至连原来没教过的也会，这时候我们怎么来做？

直到今天，我们的目标是希望通过Scaling让它有更强的泛化能力，但是直到今天它的泛化能力还有待大大的提高，我们在不同的层面在提高它。

最早期的时候我们用Transformer训一个模型，把所有的知识记忆下来。我们训的数据越多，我们训的算力越多，它的长时知识的记忆能力越强，也就是说它把世界上所有的知识都背下来了，并且有一定的泛化能力，可以抽象，可以做简单的推理。于是你要问一个问题，中国的首都是什么？这时候模型不需要推理，它只是从知识库里拿出来。

第二层是把这个模型进行对齐和推理，让这个模型有更复杂的推理能力以及理解我们的意图。我们需要持续的 Scaling SFT，甚至强化学习。通过人类大量的数据反馈，我们在Scaling反馈数据，让这个模型可以变的更聪明、变的更准确。

今年是RLVR（可验证奖励强化学习）爆发年。今年我们通过可验证的强化学习，原来为什么这个事情很难做呢？因为原来我们通过人类反馈，我们只能通过人类反馈数据来做，但人类反馈的数据里面噪音也非常多，而且场景也非常单一。但如果我们有一个可验证的环境，这时候我们可以让机器自己去探索、自己去发现这个反馈数据，自己来成长。

这里面难题的难题，大家一听就知道，说可验证是什么意思？比如说可验证，数学也许可以验证、编程可能可以验证，但更广泛的，比如我们说做了一个网页，这个网页好不好看，这时候可能就不大好验证了，它需要人来判断。

大家可能会问，是不是智能越来越强，我们直接把模型不停地训就行了？其实也不是。大家知道2025年初发生了什么，2025年初DeepSeek出来，很多时候叫横空出世，我觉得这个词用的挺好的，真是叫横空出世。可能对我们研究界、对产业界，甚至对很多人都是，因为大家原来在这个学术界、产业界都没有料到DeepSeek会突然出来，而且确实性能很强，而且一下子让很多人感到很震撼。

后来我们在2025年初的时候当时在想一个问题，也许在DeepSeek这种范式下，把这种Chat时代基本上差不多算是解决了，也就是说我们做的再好，也许在Chat的问题上可能做到最后跟DeepSeek差不多，或许我们在上面再个性化一点，变成有情感的Chat，或者再复杂一点。但是总的来讲，这个范式可能基本上到这快到头了，剩下更多的反而是工程和技术上的问题。

当时我们面临这么一个选择，我们怎么让这个AI下一步朝向哪个方向发展？我们当时的想法也许新的范式是让每个人能够用AI做一件事情，这可能是下一个范式，原来是Chat，现在是真的做事了，所以新的范式开启了。

还面临的选择，因为这个范式开启，有很多种开启方法。大家还记得年初的时候，我记得有两个问题：一个是简单的编程，做Coding、做Agent；第二是我们可以用AI来帮我们做研究，类似于DeepResearch，甚至写一个复杂的研究报告。这两条思路可能还不大一样，这也是一个选择的结果。一方面是做Thinking，我们加上一些Coding的场景；另外一方面可能要跟环境交互，让这个模型变的更加交互、更加生动，怎么来做？

后来我们选了左边这条路，我们让它有Thinking能力。但是我们也没有放弃右边，我们大概在7月28号做了一件事情，相对来讲还比较成功的，把Coding、Agentic、Reasoning能力整合在一起了。整合在一起可能也没那么容易，原来一般来讲大家做模型的时候，Coding相对来讲可能单独拿出去做，Coding变成Coding，推理变成推理，甚至有时候会数学变成数学，但这种做法往往会损失掉其他的能力。所以我们当时是把这三个能力基本上合在一起，让三个能力都相对比较平衡。

下面一个问题，下一步我们还能继续Scaling吗？我们下一个AGI范式是什么？我们面临更多的一些挑战。

我们刚才做了一些开源，可能有些人会觉得很兴奋，觉得中国的大模型好像已经超过美国了。其实可能真正的答案是我们差距也许还在拉大，因为美国那边的大模型更多的还在闭源，我们是在开源上面玩了让自己感到高兴的，我们的差距并没有像我们想象的那样好像在缩小。有些地方我们可能做的还不错，我们还要承认自己面临的一些挑战和差距。

我突然想起2019年，这个PPT原来真的是跟阿里巴巴合作的时候，当时让我给出一页PPT，我当时给出了这一页PPT，就是AGI-Next 30，未来30年我们应该做什么。

这个图是我截屏下来的，Next AI，我们说在2019年的时候，未来30年，我们应该做让机器有推理能力、有记忆能力、有意识。我们现在差不多在这里面做了一定的推理能力，大家应该都有一点点共识。记忆能力有一部分，但意识还没有，这是我们在努力的。

## 杨植麟

杨植麟的分享，充满了技术与公式，这里简单总结下：
通过Token Efficiency和Long Context两个维度优化，最终能实现更强的Agent智能。

K2已成为中国首个Agent模型，可完成两三百步工具调用，在HLE等核心评测上超越OpenAI。

## 林俊旸

我们做开源做的比较久，2023年8月3日开始做开源，很多人问我们为什么做开源这一件事情？很多事情都有机缘巧合的成分在这里，反正开源一路做下来之后做了很多，至少还是比较工业的事情。东西不多，基本是一些脚本大家在上面看就可以。我们的模型是比较多的，为什么相对比较多？以前有很多人不理解我们为什么做小模型，但是今天大家都明白小模型还是挺有价值。

小模型最终起源于我们内部用来做实验的1.8B模型，我们做预训练，资源毕竟有限，你做实验的话不能通通用7B的实验来验，就拿1.8B的来验。当时我的师弟跟我说我们要把这个模型开源出去，我非常不理解。我说这个模型在2023年几乎是一个不可用的状态，为什么要开源出去？他跟我说7B很消耗机器资源，很多硕士生和博士生没有机器资源做实验，如果1.8B开源出去的话，很多同学就有机会毕业了，这是很好的初心。

干着干着手机厂商跑来跟我们说7B太大，1.8B太小，能不能给我们干一个3到4B的，这个容易，没有什么很难的事情。一路干下来型号类型越来越多，跟服务大家多多少少有一点关系。

但是我们自己的内心追求的不仅仅是服务开发者或者服务科研人员，我们看一看能不能做一个Multimodal Foundation Agent，我特别相信这件事情。如果追溯到更远的话，刚才唐老师说我们当年还在合作的时候，当时就在大干多模态，现在想想这是一个激情岁月。2023年的时候大模型是一个大家都不要的东西，多多少少有那么几分大炼钢铁的成分，多模态是我们延续下来一直想做的事情。

为什么呢？我们觉得如果你想做一个智能的东西，天然的应该是Multimodal，当然带有不同看法，各个学者都有一些看法，多模态能不能驱动智力的问题。我懒得吵这个架，人有眼睛和耳朵可以做更多的事情，我更多的考虑是Foundation有更多的生产力，能不能更好的帮助人类，毫无疑问我们应该做视觉，我们应该做语音。

更进一步我们要做什么东西呢？Omni的模型不仅仅是我能够理解文本、视觉、音频，我们可能还让它生成文本、音频，今天我们已经做到了，但是我们还没有做到把视觉生成结合在一起。如果做到三进三出，我觉得会是至少我个人喜欢的东西。

## 圆桌对话：中国AI的下一步

姚顺雨： 我觉得模型分化有两个大的感受，一个感受是To C和To B发生了明显的分化，另外一个感受是垂直整合这条路，以及模型和应用分层这条路，也开始出现了分化。

我先说第一点，我觉得很明显的是当大家想到AI就是两个，ChatGPT，另外一个Claude Code，是做To C和To B的典范。非常有意思的一点是我们今天用ChatGPT和去年相比的话，感受差别不是太大。但是相反，Coding夸张一点来讲，已经在重塑整个计算机行业做事的方式，人已经不再写代码，而是用英语和电脑去交流。

我觉得很核心的一点，对于To C来说，大部分人大部分时候不需要用到这么强的智能，可能今天用ChatGPT和去年相比，写抽象代数和伽罗瓦理论的能力变强了，但是大部分人大部分时候感受不到。大部分人尤其是在中国更多像是搜索引擎的加强版，很多时候也不知道该怎么去用，把它的智能给激发出来。

但对于To B来说，很明显的一点是智能越高，代表生产力越高，值钱的也越来越多，这些东西都是相关的。

对于To B来讲，还有一个很明显的点，大部分时候很多人就愿意用最强的模型。一个模型是200美元/月，第二强或者差一些的模型是50美元/月、20美元/月，我们今天发现很多美国的人愿意花溢价用最好的模型。可能他的年薪是20万美元，每天要做10个任务，一个非常强的模型可能10个任务中八九个做对了，差的是做对五六个，问题是你不知道这五六个是哪五六个的情况下，需要花额外精力去监控这个事情。

我觉得无论是人还是模型，在To B这个市场上发现了一个很有意思的现象，强的模型和稍微差点或者弱的模型它的分化会越来越明显。我觉得这是第一点观察。

第二点观察，垂直整合这条路和模型应用分层这条路的区别。我觉得一个比较好的例子，比如ChatGPT Agent，相比于用Claude或者Gemini加上Manus这样的应用层产品，过去大家会认为当你有垂直整合能力肯定会做的更好，但起码今天来看并不一定。首先模型层和应用层需要的能力还是挺不一样的，尤其是对于To B或者生产力这样的场景来说，可能更大的预训练还是一个非常关键的事情，这个事情对于产品公司确实很难做，但是想要把这么一个特别好的模型用好，或者这样的模型有它的溢出能力，也需要在应用侧或者环境这一侧做很多相应的事情。

我们会发现其实在To C的应用上垂直整合还是成立的，无论是ChatGPT还是豆包，模型和产品是非常强耦合去紧密迭代的。但是对于To B来说这个趋势似乎是相反的，模型在变得越来越强、越来越好，但同样会有很多应用层的东西应用好的模型在不同的生产力环节。

我觉得我们会思考怎么样能够让今天的大模型或者说AI的发展能够给用户提供更多价值。很核心的思考是我们发现很多时候我们的环境来讲，或者更强的模型，很多时候需要的是额外的Context。

我最近经常举一个例子，比如我想问我今天该去吃什么？其实你今天问ChatGPT和你去年问或者明天问都会差很多。这个事情想要变好，不是说你需要更大的模型、更强的预训练、更强的强化学习、更强的Agent环境或者更强的搜索引擎，这个问题可能需要更多额外的输入，或者我们叫Context。如果它知道我今天特别冷，我需要吃些暖和的，我在今天这样的范围活动，可能我老婆在另一个地方吃什么等各种各样的事情。其实回答这样的问题，更多的是额外的输入。比如我和老婆聊了很多天，我们可以把聊天记录转发给元宝，或者把额外的输入用好，反而会给用户带来很多额外的价值。这是我们对To C上的思考。

在To B在中国确实是很难的事情，生产力的革命，包括我们今天很多中国的公司做Coding Agent需要打很多海外市场。我们会思考怎么把自己先服务好，像创业公司做Coding这个事情和大公司做Coding这个事情，一个区别是作为大公司本身就已经有各种各样的应用场景、各种各样需要生产力变得更好的地方。如果我们的模型能够在这个地方做得更好，不仅这个模型会有自己独特的优势，不仅我们公司本身能得到很好的发展，很重要的一点是对于真实世界场景的数据捕捉会是一个很有意思的事情。比如说Claude这些创业公司，他们想要去做更多的Coding Agent的数据，需要找数据厂商去标注这个数据，他们需要利用各种各样的软件工程师去想我要去标什么样的数据。这个事情是数据公司一共就这么几家，一共招了这么多人，最终你会受限。但如果你是一个10万人的公司，可能会有一些有意思的尝试，怎么把真实世界的数据利用好，而不是仅仅依赖于标注商或者协议。

## 中国AI的未来

我挺想问大家一个问题，在三年和五年以后，全球最领先的AI公司是中国团队的概率有多大？ 我们从今天的跟随者变成未来的引领者，这个过程包括关键条件到底还有哪些需要去做好的？就是未来3-5年，我就想这个概率有多大，以及需要哪些关键条件？

顺雨经历过硅谷跟中国两个体感的，你对概率的判断和需要哪些关键条件的判断是怎么样的？

姚顺雨： 我觉得概率还挺高的，我还是挺乐观的。目前看起来，任何一个事情一旦被发现，在中国就能够很快的复现，在很多局部做得更好，包括之前制造业、电动车这样的例子已经不断地发生。

我觉得可能有几个比较关键的点，一个可能是中国的光刻机到底能不能突破，如果最终算力变成了Bottleneck，我们能不能解决算力问题。目前看起来，我们有很好的电力优势，有很好的基础设施的优势。主要的瓶颈，一个是产能，包括光刻机，以及软件生态。如果这个问题解决，我觉得会是很大的帮助。

另一个问题，除了To C之外，能不能有更成熟或者更好的To B的市场，或者有没有机会在国际的商业环境竞争。今天我们看到很多做生产力或者做To B的模型或者应用，还是会诞生在美国，因为支付意愿更强，文化更好。今天在国内做这个事情很难，所以大家都会选择出海或者国际化的事情，这两个是比较大的客观上的因素。

更重要的是主观上的因素，最近我在跟很多人聊天，我们的感受是在中国有非常多非常强的人才，任何一个事情只要被证明能做出来，很多人都会非常积极地尝试，并且想做得更好。

我觉得中国想要突破新的范式或者做非常冒险事情的人可能还不够多，这里面有经济环境、商业环境包括文化的因素。如果增加一点，主观上有没有更多有创业精神或者冒险精神的人，真的想要去做前沿探索或者新的范式突破的事情。目前来看，一个范式一旦发生，我们可以用很少的卡、很高的效率去局部做得更好，我们到底能不能引领新的范式，这可能是今天中国唯一要解决的问题，因为其他所有做的事情，无论是商业，还是产业设计，还是做工程，我们某种程度上已经比美国做得更好。

李广密： 我再Follow顺雨一个问题，你对中国Lab里面的研究文化有什么要呼吁的吗？你也感受过OpenAI也好，包括湾区DeepMind研究文化，中国的研究文化跟美国的研究文化有什么差异的地方？这个研究文化对作为一个AI Native的公司，有哪些根本性的影响？你有呼吁和建议吗？

姚顺雨： 我觉得每个地方的研究文化都很不一样，美国实验室的区别可能比中美实验室的差别还要大，在中国也一样。

我个人觉得有两点，一点是说在中国大家还是更喜欢做更安全的事情，比如说今天预训练这个事情已经被证明可以做出来了，其实这个事情也非常难做，有很多技术问题要解决，但只要这件事情一旦被证明能做出来，我们都很有信心几个月或者一段时间内就把这个问题搞清楚。但如果今天让一个人说探索一个长期记忆或者持续学习，这个事情大家不知道怎么做、不知道能不能做起来，这个事情还是比较困难的。可能不只是大家更喜欢做确定性的事情、不太愿意做创新性的事情，很重要的一点是文化的积累或者整体的认知，其实是需要时间沉淀的事情。OpenAI在2022年就开始做这个事情了，国内2023年开始做，对这个东西的理解会有一些差异，或者说这个差距没有那么大，我觉得可能很多也就是时间问题。当你积累了文化或者底蕴更深的时候，潜移默化的程度可能会影响人的做事方式，但是它很微妙，很难通过榜单去体现。

中国对于刷榜或者数字看得更重一些，包括DeepSeek做得比较好的一点，他们可能没有那么关注榜单的数字，可能会更注重，第一，什么是正确的事情；第二，什么是你自己能体验出好或者不好的。我觉得这还是挺有意思的，因为你看Claude模型可能在编程或者软件工程的榜单上也不是最高的，但大家都知道这个东西是最好用的。我觉得这还是需要大家能够走出这些榜单的束缚，能够坚持自己觉得是不是正确的过程。

林俊旸： 这个问题是个危险的问题，理论上这个场合是不可以泼冷水的，但如果从概率上来说，我可能想说一下我感受到的中国和美国的差异。比如说美国的Compute可能整体比我们大1-2个数量级，但我看到不管是OpenAI还是什么，他们大量的Compute投入到的是下一代的Research当中去，我们今天相对来说捉襟见肘，光交付可能就已经占据了我们绝大部分的Compute，这会是一个比较大的差异在这里。这可能是历史以来就有的问题，创新是发生在有钱的人手里，还是穷人手里，穷人不是没有机会，我们觉得这些富哥真的很浪费卡，他们训了这么多东西，可能训了很多也没什么用。但今天穷的话，比如今天所谓的算法Infra联合优化的事情，如果你真的很富，就没有什么动力去做这个事情。

我觉得可能更进一步的，刚才顺雨提到光刻机的问题，未来有可能还有一个点，如果从软硬结合的角度，是不是真的有可能做出来？比如说我们下一代这个模型和芯片，有可能是一起把它给做出来的。我在2021年的时候在做大模型，因为阿里做芯片，在找我说能不能预测一下三年之后这个模型是不是Transformer，三年之后这个模型是不是多模态，为什么是三年呢？他说我们需要三年时间才能流片。我当时的回答是三年之后在不在阿里巴巴，我都不知道！但我今天还在阿里巴巴，它果然还是Transformer，果然还是多模态，我非常懊悔为什么当时没有催他去做。当时我们的交流非常鸡同鸭讲，他给我讲了一大堆东西，我完全听不懂，我给他讲，他也不知道我们在做什么，就错过了这个机会。这个机会有没有可能再来一次？我们虽然是一群穷人，是不是穷则思变，创新的机会会不会发生在这里？

今天我们教育在变好，我属于90年代靠前一些的，顺雨属于90年代靠后一点的，我们团队里面有很多00后，我感觉大家的冒险精神变得越来越强。美国人天然有非常强烈的冒险精神，一个很典型的例子是当时电动车刚出来，甚至天棚漏水的情况下，甚至开车会意外身亡的情况下，依然会有很多富豪们都愿意去做这个事情，但在中国，我相信富豪们是不会去干这个事情的，大家会做一些很安全的事情。今天大家的冒险精神开始变得更好，中国的营商环境也在变得更好的情况下，我觉得是有可能带来一些创新的。概率没那么大，但真的有可能。

李广密： 如果派一个数字呢？

林俊旸： 您是说百分之多少？

李广密： 对，三年到五年后，中国最领先的那个公司，是一家中国公司的概率。

林俊旸： 我觉得是20%吧，20%已经非常乐观了，因为真的有很多历史积淀的原因在这里。

唐杰： 首先我觉得确实要承认在中美，无论是做研究，尤其是企业界的AI Lab，我觉得和美国是有差距的，这是第一个。

但我觉得在未来中国，现在慢慢变得越来越好，尤其是90后、00后这一代，远远好过之前。有一次我在一个会上说我们这一代最不幸运，上一代也在继续工作，我们也在工作，所以我们还没有出头之日，很不幸的是下一代已经出来了，世界已经交给下一代了，已经把我们这一代无缝跳过了。这是开玩笑的。

中国也许的机会：

第一，一群聪明人真的敢做特别冒险的事，我觉得现在是有的，00后这一代，包括90后这一代是有的，包括俊旸、Kimi、顺雨都非常愿意冒风险来做这样的事情。

第二，咱们的环境可能更好一些，无论是国家的环境，比如说大企业和小企业之间的竞争，创业企业之间的问题，包括我们的营商环境，像刚才俊旸说的，我还在做交付，我觉得如果把这个环境建设得更好，让一群敢于冒险的聪明人有更多的时间去做这样创新的事情，比如说让俊旸有更多的时间做创新的事情，这是第二个，也许是我们政府，包括我们国家可以帮忙改善的事情。

第三，回到我们每个人自己身上，就是我们能不能坚持。 我们能不能愿意在一条路上敢做、敢冒险，而且环境还不错。我觉得环境肯定不会是最好的，永远不会想着环境是最好的，我们恰恰是幸运，我们经历环境从原来没那么好，到慢慢变得更好的一个时代，我们是经历者，也许就是财富，包括经历收获最多的人。如果我们笨笨的坚持，也许走到最后的就是我们。