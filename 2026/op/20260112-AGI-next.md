## 国产 AI 峰会发言摘录

上周六（1月10日），北京有一场“AGI-Next 前沿峰会”，由清华大学基础模型实验室主办。

![](https://cdn.beekka.com/blogimg/asset/202601/bg2026011406.webp)

中国顶尖的 AI 大模型领导者，很多都出席了。

> - 唐杰：清华大学教授，智谱创始人
> - 杨植麟：月之暗面 Kimi 创始人
> - 林俊旸：阿里 Qwen 技术负责人
> - 姚顺雨：OpenAI 前核心研究者、腾讯 AI 新部门负责人

他们谈了对大模型和中国 AI 发展的看法，网上有[发言实录](https://www.53ai.com/news/LargeLanguageModel/2026011069524.html)。

内容非常多，有意思的发言也很多，下面是我摘录的部分内容。

## 一、唐杰的发言

### 1、智谱的起源

2019年，我们开始研究，能不能让机器像人一样思考，当时就从清华成果转化，在学校的大力支持下，成立了智谱这么一家公司，我现在是智谱的首席科学家。

那个时候，我们实验室在图神经网络、知识图谱方面，在国际上做的还行，但我们坚定地把这两个方向暂停了，暂时不做了，所有的人都转向做大模型。

### 2、泛化和 Scaling

我们希望机器有泛化能力，我教它一点点，它就能举一反三。就和人一样，教小孩子的时候，我们总希望教三个问题，他就会第四个、第十个，甚至连没教过的也会。怎么让机器拥有这种能力？

目前为止，我们主要通过 Scaling（规模化）达到这个目标，在不同层面提高泛化能力。

（1）我们最早期用 Transformer 训练模型，把所有的知识记忆下来。训练数据越多、算力越多，模型的记忆能力就越强，也就是说，它把世界上所有的知识都背下来了，并且有一定的泛化能力，可以抽象，可以做简单的推理。比如，你问中国的首都是什么？这时候模型不需要推理，它只是从知识库里拿出来。

（2）第二层是把模型进行对齐和推理，让它有更复杂的推理能力，以及理解我们的意图。我们需要持续的 Scaling SFT（Supervised Fine-Tuning，监督式微调），甚至强化学习。通过人类大量的数据反馈，不断 Scaling 反馈数据，可以让模型变得更聪明、更准确。

（3）今年是 RLVR（强化学习与可验证奖励）爆发年。这里的“可验证”是什么意思？比如，数学可以验证、编程可能可以验证，但更广泛地，网页好不好看，就不大好验证了，它需要人来判断。

这就是为什么这个事情很难做，我们原来只能通过人类反馈数据来做，但人类反馈的数据里面噪音也非常多，而且场景也非常单一。

如果我们有一个可验证的环境，这时候我们可以让机器自己去探索、自己去发现这个反馈数据，自己来成长。这是我们面临的一个挑战。

### 3、从 Chat 到做事：新范式的开始

大家可能会问，是不是不停地训练模型，智能就越来越强？其实也不是。

2025年初，DeepSeek 出来，真是横空出世。大家原来在学术界、产业界都没有料到 DeepSeek 会突然出来，而且性能确实很强，一下子让很多人感到很震撼。

我们当时就想一个问题，也许在 DeepSeek 这种范式下，Chat（对话）差不多算是解决了。也就是说我们做得再好，在 Chat 上可能做到最后跟 DeepSeek 差不多。或许我们可以再个性化一点，变成有情感的 Chat，或者再复杂一点，但是总的来讲，这个范式可能基本到头了，剩下更多的反而是工程和技术的问题。

那么，AI 下一步朝哪个方向发展？我们当时的想法是，让每个人能够用 AI 做一件事情，这可能是下一个范式，原来是 Chat，现在是真的做事了。

当时有两个方向，一个是编程，做 Coding、做 Agent；另一个是用 AI 来帮我们做研究，类似于 DeepResearch，甚至写一个复杂的研究报告。我们现在的选择是把 Coding、Agentic、Reasoning 这三个能力整合在一起。

## 二、林俊旸的发言

### 4、千问是怎么开源的

千问的开源模型比较多，很多人问这是为什么？

这起源于2023年8月3日，我们开源了一个小模型，它是我们内部用来做实验的 1.8B 模型。我们做预训练，资源毕竟有限，你做实验的话不能通通用 7B 的模型来验，就拿 1.8B 的来验。

当时我的师弟跟我说，我们要把这个模型开源出去。我非常不理解，我说这个模型在2023年几乎是一个不可用的状态，为什么要开源出去？他跟我说 7B 很消耗机器资源，很多硕士生和博士生没有机器资源做实验，如果 1.8B 开源出去的话，很多同学就有机会毕业了，这是很好的初心。

干着干着，手机厂商跑来跟我们说 7B 太大，1.8B 太小，能不能给我们干一个 3B 或 4B 的，这个容易，没有什么很难的事情。一路干下来，型号类型越来越多，跟服务大家多多少少有一点关系。

### 5、我们的追求是多模态模型

我们自己内心追求的，不仅仅是服务开发者或者服务科研人员，而是能不能做一个 Multimodal Foundation Agent（多模态基础智能体）。

我特别相信这件事情，2023年的时候大模型是一个大家都不要的东西，多多少少有那么几分大炼钢铁的成分，多模态是我们从那时就一直想做的事情。

为什么呢？我们觉得如果你想做一个智能的东西，天然的应该是 Multimodal（多模态），当然带有不同看法，各个学者都有一些看法，多模态能不能驱动智力的问题。我懒得吵这个架，人有眼睛和耳朵可以做更多的事情，我更多的考虑是 Foundation（基础智能体）有更多的生产力，能不能更好地帮助人类，毫无疑问我们应该做视觉，我们应该做语音。

更进一步，我们要做什么东西呢？Omni 的模型（全模态模型）不仅仅是能够理解文本、视觉、音频，我们可能还让它生成文本、音频。今天我们已经做到了，但是我们还没有做到把视觉生成结合在一起。如果做到三进三出，我觉得至少是我个人喜欢的东西。

## 三、姚顺雨的发言

### 6、To C 和 To B 的差异

我的一个观察是 To C（消费者模型）和 To B（商业用户模型）发生了明显的分化。

大家一想到 AI，就会想到两个东西，一个是 ChatGPT，另外一个是 Claude Code。它们就是做 To C 和 To B 的典范。

对于 To C 来说，大部分人大部分时候不需要用到那么强的智能，可能今天的 ChatGPT 和去年相比，研究分析的能力变强了，但是大部分人大部分时候感受不到，更多把它当作搜索引擎的加强版，很多时候也不知道该怎么去用，才能把它的智能激发出来。

但对于 To B 来说，很明显的一点是智能越高，代表生产力越高，也就越值钱。所以，大部分时候很多人就是愿意用最强的模型。一个模型是200美元/月，第二强或者差一些的模型是50美元/月、20美元/月，我们今天发现很多美国的人愿意花溢价用最好的模型。可能他的年薪是20万美元，每天要做10个任务，一个非常强的模型可能10个任务中八九个做对了，差的是做对五六个，问题是你不知道这五六个是哪五六个的情况下，需要花额外精力去监控这个事情。

所以，在 To B 这个市场上，强的模型和稍微弱点的模型，分化会越来越明显。

### 7、垂直整合和模型应用分层

我的第二点观察是，基础模型和上层应用，到底是垂直整合，还是模型应用分层，也开始出现了分化。

比如，ChatGPT Agent 是垂直整合，Claude（或者 Gemini）+ Manus 是模型应用分层。过去大家认为，当你有垂直整合能力肯定做得更好，但起码今天来看并不一定。

首先，模型层和应用层需要的能力还是挺不一样的，尤其是对于 To B 或者生产力这样的场景来说，可能更大的预训练还是一个非常关键的事情，这个事情对于产品公司确实很难做。但是想要把这么一个特别好的模型用好，或者让这样的模型有溢出能力，也需要在应用侧或者环境这一侧做很多相应的事情。

我们发现，其实在 To C 的应用上，垂直整合还是成立的，无论 ChatGPT 还是豆包，模型和产品是非常强耦合、紧密迭代的。但是对于 To B 来说，这个趋势似乎是相反的，模型在变得越来越强、越来越好，但同样会有很多应用层的东西将好的模型用在不同的生产力环节。

### 8、需要更大的 Context

怎么让今天的大模型或者 AI 能够给用户提供更多价值？我们发现，很多时候需要的是额外的 Context（上下文）。

比如，我问 AI 今天该去吃什么？其实，你今天问 ChatGPT 和你去年问或者明天问，答案应该会差很多。这个事情想要做好，不是说你需要更大的模型、更强的预训练、更强的强化学习，而是可能需要更多额外的输入，或者叫 Context。如果它知道我今天特别冷，我需要吃些暖和的，我在今天这样的范围活动，可能我老婆在另一个地方吃什么等各种各样的事情，它的回答就会更好。

回答这样的问题，更多需要的是额外的输入。我和老婆聊了很多天，我们可以把聊天记录转发给元宝，把额外的输入用好，会给用户带来很多额外的价值。这是我们对 To C 的思考。

## 四、圆桌对话：中国 AI 的未来

李广密（主持人）：我想问大家一个问题，在三年和五年以后，全球最领先的 AI 公司是中国团队的概率有多大？我们从今天的跟随者变成未来的引领者，这个过程到底还有哪些需要去做好？

### 9、姚顺雨的回答

我觉得概率还挺高的，我挺乐观的。目前看起来，任何一个事情一旦被发现，在中国就能够很快的复现，在很多局部做得更好，包括之前制造业、电动车这样的例子已经不断地发生。

我觉得可能有几个比较关键的点。

（1）中国的光刻机到底能不能突破，如果最终算力变成了瓶颈，我们能不能解决算力问题。

（2）能不能有更成熟的 To B 市场。今天我们看到很多做生产力或者做 To B 的模型和应用，还是会诞生在美国，因为支付意愿更强，文化更好。今天在国内做这个事情很难，所以大家都会选择出海或者国际化。这和算力是比较大的客观因素。

（3）更重要的是主观因素，我觉得中国想要突破新的范式或者做非常冒险事情的人可能还不够多。也就是说，有没有更多有创业精神或者冒险精神的人，真的想要去做前沿探索或者范式突破的事情。我们到底能不能引领新的范式，这可能是今天中国唯一要解决的问题，因为其他所有做的事情，无论是商业，还是产业设计，还是做工程，我们某种程度上已经比美国做得更好。

### 10、林俊旸的回答

这个问题是个危险的问题，理论上这个场合是不可以泼冷水的，但如果从概率上来说，我可能想说一下我感受到的中国和美国的差异。比如说，美国的 Compute（算力）可能整体比我们大1-2个数量级，但我看到不管是 OpenAI 还是什么，他们大量的算力投入到的是下一代研究当中去，我们今天相对来说捉襟见肘，光交付可能就已经占据了我们绝大部分的算力，这会是一个比较大的差异。

这可能是历史上就有的问题，创新是发生在有钱的人手里，还是穷人手里。穷人不是没机会，我们觉得这些富哥真的很浪费，他们训练了这么多东西，可能训练了很多也没什么用。但今天穷的话，比如今天所谓的算法 Infra（基础设施）联合优化的事情，如果你真的很富，就没有什么动力去做这个事情。

未来可能还有一个点，如果从软硬结合的角度，我们下一代的模型和芯片的软硬结合，是不是真的有可能做出来？

2021年，我在做大模型，阿里做芯片的同学，找我说能不能预测一下，三年之后这个模型是不是 Transformer，是不是多模态。为什么是三年呢？他说我们需要三年时间才能流片。我当时的回答是三年之后在不在阿里巴巴，我都不知道！但我今天还在阿里巴巴，它果然还是 Transformer，果然还是多模态，我非常懊悔为什么当时没有催他去做。当时我们的交流非常鸡同鸭讲，他给我讲了一大堆东西，我完全听不懂，我给他讲，他也不知道我们在做什么，就错过了这个机会。这个机会有没有可能再来一次？我们虽然是一群穷人，是不是穷则思变，创新的机会会不会发生在这里？

今天我们教育在变好，我属于90年代靠前一些的，顺雨属于90年代靠后一点的，我们团队里面有很多00后，我感觉大家的冒险精神变得越来越强。美国人天然有非常强烈的冒险精神，一个很典型的例子是当时电动车刚出来，甚至开车会意外身亡的情况下，依然会有很多富豪们都愿意去做这个事情，但在中国，我相信富豪们是不会去干这个事情的，大家会做一些很安全的事情。今天大家的冒险精神开始变得更好，中国的营商环境也在变得更好的情况下，我觉得是有可能带来一些创新的。概率没那么大，但真的有可能。

三年到五年后，最领先的 AI 公司是一家中国公司的概率，我觉得是20%吧，20%已经非常乐观了，因为真的有很多历史积淀的原因在这里。

### 11、唐杰的回答

首先我觉得确实要承认，无论是做研究，尤其是企业界的 AI Lab，和美国是有差距的，这是第一点。

我们做了一些开源，可能有些人觉得很兴奋，觉得中国的大模型好像已经超过美国了。其实可能真正的情况是我们的差距也许还在拉大，因为美国那边的大模型更多的还在闭源，我们是在开源上面玩了让自己感到高兴的，我们的差距并没有像我们想象的那样好像在缩小。有些地方我们可能做的还不错，我们还要承认自己面临的一些挑战和差距。

但我觉得，现在慢慢变得越来越好。

（1）90后、00后这一代，远远好过之前。一群聪明人真的敢做特别冒险的事，我觉得现在是有的，00后这一代，包括90后这一代是有的，包括俊旸、Kimi、顺雨都非常愿意冒风险来做这样的事情。

（2）咱们的环境可能更好一些，无论是国家的环境，比如说大企业和小企业之间的竞争，创业企业之间的问题，包括我们的营商环境。

（3）回到我们每个人自己身上，就是我们能不能坚持。我们能不能愿意在一条路上敢做、敢冒险，而且环境还不错。如果我们笨笨的坚持，也许走到最后的就是我们。


---


美中AI竞争，中国顶尖的AI大模型领导者齐聚一堂，和外界打鸡血不同，他们更冷静自评整体行业反超的机率低过20%，算力的规模小太多，而且确实美中的研究和企业的AI Lab都有差距。但是他们“穷有穷的做法”。

与会者普遍认为，大模型竞争已从聊天能力转向能完成复杂任务的智能体阶段。 2026年将是模型真正创造商业价值的关键年份，但多位核心人物将中国在下一代范式中领先的机率评估为不超过20%。

### 产业现况：Chat时代结束，做事时代开始

唐杰直言：「DeepSeek出来后，Chat这一代问题基本已经解决。继续优化大概率只是性能接近，或在个性化、情感化上做改进，空间正在迅速收敛。」

这迫使团队思考下一步。 「新的范式不再只是对话，而是让每个人真正用AI完成一件具体的事情。从Chat走向做事，是明显的转折点。」智谱团队最终把所有精力放在了Coding上。

RLVR（可验证强化学习）成为当前关键技术路径。唐杰解释：「过去强化学习难以大规模推进，核心是依赖人类反馈，噪音大、覆盖场景有限。引入可验证环境后，模型可以自主探索、自动获得反馈。但难点在于，数学、编程等领域容易定义可验证，网页是否美观、交互是否合理仍需人工判断。当前RLVR面临的挑战是：可验证场景正在逐渐耗尽。」

杨植麟则从Scaling Law角度分析：「今天所有模型架构的迭代，都是为了寻找一条更接近左下角的线。互联网存量数据有限，高品质数据成长速度赶不上模型迭代速度，所以Token efficiency决定智能上限。」他透露Kimi采用的MUON二阶优化器带来两倍Token efficiency提升，而新架构Kimi Linear在百万Context下速度优势达6到10倍。

林俊旸观察到中美市场差异：「跟美国API厂商聊，他们没想到Coding消耗量那么大。在美国基本全都是Coding，中国真的没那么大。」他也指出中国开源模型的成就：「在Artificial Analysis榜单上，前五名中的蓝色模型几乎全部来自中国，说明中国在开源大模型领域已经形成非常显著的影响力。」

### ToB与ToC的路线分化

姚顺雨指出toC和toB的逻辑正在分化：「我们今天用ChatGPT和去年相比感受差别不大，但Coding已经在重塑整个电脑行业做事的方式。对于toC，大部分人不需要用到这么强的智能；但对于toB，智能越高代表生产力越高。」

他解释溢价逻辑：「一个年薪20万美元的人，每天做10个任务，强模型可能做对八九个，差的做对五六个。问题是你不知道哪五六个是对的，需要额外精力监控。所以很多人愿意花200美元/月用最好的模型。」

垂直整合也不再是唯一答案。姚顺雨观察：「在toC应用上垂直整合还成立，但对于toB趋势似乎相反。模型层偏向硬核工业化，拼预训练与算力；应用层偏向业务工程化，拼流程与交付。未来toB市场可能走向分层结构：最强的模型配合最懂场景的应用团队。」

### 自主学习已经在发生

姚顺雨认为自主学习是现在进行式：「ChatGPT在利用用户数据学习聊天风格，Claude已经写了这个项目95%的程式码。很多人说2026年看到信号，我觉得2025年就看到了。Cursor每几个小时都会用最新用户数据学习。」

他提出关键问题：「最大的问题是想像力。如果2026年我们宣布实现了自我学习，应该用什么任务衡量？是一个赚钱的交易系统，还是解决了人类之前没法解决的科学问题？」

林俊旸关注主动性带来的安全顾虑：「AI有没有可能自主思考去做事情？我最担心的不是它讲不该说的话，而是做不该做的事。就像培养小孩，要给它注入正确的方向。」

唐杰对2026年范式革新充满信心：「原来工业界有1万片卡，学校是0片，现在很多学校已经有卡了。创新的出现一定是某个事情有大量投入，且efficiency变成瓶颈。继续Scaling有收益，但花掉20亿收益很小就不值得了。也许我们未来可以定义Intelligence efficiency，用多少投入能获得智能的增量。」

他也点出下一步技术方向：「多模态感知统合会成为今年重点。人通过视觉、听觉、触觉形成整体认知，模型如何建立类似的原生多模态机制是关键方向。记忆与持续学习、反思与自我认知能力，都有可能出现新范式变革。」

### Agent之年的展望

姚顺雨分享关键观察：「即使今天模型不再变好，把这些模型部署到各种公司，已经能带来今天10倍或100倍的收益，能对GDP产生5%-10%的影响，但今天影响还不到1%。」

他强调教育的重要性：「中国能做到最大有意义的事情是更好的教育。更多时候不是AI替代人类工作，而是会使用工具的人在替代不会使用工具的人。」

林俊旸指出长尾问题是AGI的魅力：「今天一个用户寻遍各处都找不到能帮他解决问题的，但在那一刻感受到AI的能力，这就是AI最大的魅力。」

他也点出当前局限：「我们现在交互的环境还不够复杂，都是电脑环境。做AlphaFold距离制药还有一段距离，因为要做实验才能得到反馈。有没有可能未来AI环境复杂到真实世界，指挥机器人做实验？这要跟具身智能结合。」

唐杰提出Agent落地的关键因素：「第一，Agent有没有解决有价值的事情；第二，Cost有多大；第三，做应用的速度。大模型现在更多是拼速度、拼时间。」

### 中国反超的机率约20 %

关于「中国能否反超」这一议题，峰会呈现出一种「结构性冷静」。尽管市场热衷于讨论「崛起」与「占榜」，但与会者普遍将中国领先新范式的机率上限压至20%。

### 新范式是唯一要解决的问题

姚顺雨对中国反超持审慎乐观态度：「机率还挺高的，我还是挺乐观的。任何事情一旦被发现，在中国就能很快复现，在很多局部做的更好，包括之前制造业、电动车这样的例子已经不断发生。」

但他随即指出核心挑战：「中国想要突破新范式或做非常冒险事情的人可能还不够多，这里面有经济环境、商业环境包括文化的因素。

我们到底能不能引领新的范式，这可能是今天中国唯一要解决的问题，因为其他所有做的事情，无论是商业、产业设计还是做工程，我们某种程度上已经比美国做的更好。 」

他也点出几个客观限制因素：「一个是中国的光刻机到底能不能突破，如果最终算力变成Bottleneck，我们能不能解决算力问题。目前我们有很好的电力优势、基础设施优势，主要瓶颈是产能、光刻机，以及软体生态。

另一个问题是除了toC之外，能不能有更成熟的toB市场，或者有没有机会在国际商业环境竞争。今天很多做生产力或toB的模型应用还是诞生在美国，因为支付意愿更强、文化更好。 」

### 文化积累与榜单束缚

姚顺雨特别提到文化积累的重要性：「可能不只是大家更喜欢做确定性的事情、不太愿意做创新性的事情，很重要的一点是文化的积累或者整体的认知，其实是需要时间沉淀的事情。OpenAI在2022年就开始做这个事情了，国内2023年开始做，对这个东西的理解会有一些差异。我觉得可能很多也就是时间问题。」

他以DeepSeek和Claude为例说明榜单思维的问题：「中国对刷榜或数字看的更重。DeepSeek做的比较好的一点，是他们可能没有那么关注榜单的数字，更注重什么是正确的事情、什么是你自己能体验出好或不好的。

你看Claude模型可能在编程或软体工程的榜单上也不是最高的，但大家都知道这个东西是最好用的。我觉得这还是需要大家能够走出这些榜单的束缚，能够坚持自己觉得是不是正确的过程。 」

### 算力投入结构的本质差异

阿里千问技术负责人林俊旸从算力投入角度给出更谨慎的评估：「美国的Computer可能整体比我们大1-2个数量级，但我看到不管是OpenAI还是什么，他们大量的Computer投入到的是下一代的Research当中去。

我们今天相对来说捉襟见肘，光交付可能就已经占据了我们绝大部分的Computer，这会是一个比较大的差异。 」

但他也看到穷则生变的机会：「创新是发生在有钱人手里，还是穷人手里？穷人不是没有机会，我们觉得这些富哥真的很浪费卡，他们训了很多可能也没什么用。但今天穷的话，比如今天所谓的演算法Infra联合优化的事情，如果你真的很富，就没有什么动力去做这个事情。」

林俊旸分享了一个遗憾的故事：「2021年我在做大模型，因为阿里做晶片，他们找我说能不能预测一下三年之后这个模型是不是Transformer、是不是多模态。

我当时的回答是三年之后在不在阿里巴巴我都不知道！但我今天还在阿里巴巴，它果然还是Transformer，果然还是多模态。我非常懊悔为什么当时没有催他去做。这个机会有没有可能再来一次？我们虽然是一群穷人，是不是穷则生变，创新的机会会不会发生在这里？ 」

对于年轻一代，他保持乐观：「今天大家的冒险精神开始变的更好。美国人天然有非常强烈的冒险精神，当时电动车刚出来，甚至天棚漏水、开车会意外身亡的情况下，依然会有很多富豪们都愿意去做这个事情。中国的营商环境也在变的更好的情况下，我觉得是有可能带来一些创新的。」

「机率没那么大，但真的有可能。20%吧，已经非常乐观了。今天你干这一行就不能恐惧，必须得有非常强的心态。」他补充道，

「我觉得还是看初心，我们的模型为人类社会带来什么价值。只要能为人类社会带来充分价值，就算不是最强的，我也愿意接受。」

笨笨的坚持

唐杰首先承认差距：「确实要承认在中美，无论是做研究，尤其是企业界的AI Lab，我觉得和美国是有差距的。但我觉得未来中国现在慢慢变的越来越好，尤其是90后、00后这一代，远远好过之前。」

他提出中国可能的三个机会：「第一，一群聪明人真的敢做特别冒险的事，90后、00后这一代是有的，包括俊旸、Kimi、顺雨都非常愿意冒风险来做这样的事情。

第二，我们的环境可能更好一些，无论是国家的环境、大企业和小企业之间的竞争、营商环境。像俊旸说的，他还在做交付，如果把这个环境建设的更好，让敢于冒险的聪明人有更多的时间去做创新的事情，这是政府和国家可以帮忙改善的事情。

第三，回到每个人自己身上，我们能不能坚持，能不能愿意在一条路上敢做、敢冒险。 」

「我觉得环境肯定不会是最好的，永远不会想着环境是最好的。我们恰恰是幸运，我们经历环境从原来没那么好到慢慢变得更好的一个时代。我们是经历者，也许就是财富，包括经历收获最多的人。如果我们笨笨的坚持，也许走到最后的就是我们。」唐杰总结道。
